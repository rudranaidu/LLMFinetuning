# LLMFinetuning


| Day  | Project                                       | Model                                | Dataset                           | Goal                                          |
| ---- | --------------------------------------------- | ------------------------------------ | --------------------------------- | --------------------------------------------- |
| 3-4  | 🧠 **Fine-tune GPT2 on Custom Chat Dataset**  | `gpt2`                               | Your own Q\&A or dialogue dataset | Learn full fine-tuning                        |
| 5    | 🔁 **Instruction Tuning TinyLlama**           | `TinyLlama/TinyLlama-1.1B-Chat`      | Alpaca-style JSON                 | Practice SFT (Supervised Fine-Tuning)         |
| 6    | 🔧 **Apply LoRA on LLaMA2 or Mistral**        | `mistralai/Mistral-7B-Instruct-v0.1` | Small instruction dataset         | Learn PEFT with 4-bit quant                   |
| 7    | 📊 **Fine-tune T5 for Text Summarization**    | `t5-small`                           | CNN/DailyMail (or custom)         | Learn encoder-decoder tuning                  |
| 8–10 | 🤖 **Train a Sentiment Classifier with BERT** | `bert-base-uncased`                  | IMDB                              | Learn classification with HuggingFace Trainer |
